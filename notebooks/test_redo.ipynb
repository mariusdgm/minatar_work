{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "proj_root = os.path.dirname(os.path.abspath(\".\"))\n",
    "# print(proj_root)\n",
    "sys.path.append(proj_root)\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import gym\n",
    "import yaml\n",
    "\n",
    "from minatar_dqn.replay_buffer import ReplayBuffer\n",
    "from minatar_dqn.utils.my_logging import setup_logger\n",
    "from minatar_dqn.models import Conv_QNET, Conv_QNET_one\n",
    "\n",
    "from experiments.experiment_utils import (\n",
    "    seed_everything,\n",
    "    search_files_containing_string,\n",
    "    split_path_at_substring,\n",
    "    collect_training_output_files,\n",
    ")\n",
    "\n",
    "from minatar_dqn.my_dqn import Conv_QNET, build_environment\n",
    "from minatar_dqn.redo import apply_redo_parametrization\n",
    "from experiments.experiment_utils import (\n",
    "    collect_training_output_files,\n",
    "    collect_pruning_output_files,\n",
    ")\n",
    "\n",
    "from experiments.training.training import read_config_files, get_config_paths\n",
    "\n",
    "from flatten_dict import flatten\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "sns.set()\n",
    "\n",
    "import plotly\n",
    "\n",
    "plotly.io.kaleido.scope.mathjax = None\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs_to_train': 20,\n",
       " 'seeds': [0],\n",
       " 'environments': ['breakout'],\n",
       " 'agent_params': {'agent': 'AgentDQN',\n",
       "  'args_': {'train_step_cnt': 200000,\n",
       "   'validation_enabled': True,\n",
       "   'validation_step_cnt': 125000,\n",
       "   'validation_epsilon': 0.001,\n",
       "   'replay_start_size': 5000,\n",
       "   'batch_size': 32,\n",
       "   'training_freq': 4,\n",
       "   'target_model_update_freq': 100,\n",
       "   'loss_fcn': 'mse_loss',\n",
       "   'gamma': 0.99,\n",
       "   'epsilon': {'start': 1.0, 'end': 0.01, 'decay': 250000}}},\n",
       " 'estimator': {'model': 'Conv_QNET',\n",
       "  'args_': {'conv_hidden_out_size': 32, 'lin_hidden_out_size': 128}},\n",
       " 'optim': {'name': 'Adam', 'args_': {'lr': 6.25e-05, 'eps': 0.00015}},\n",
       " 'replay_buffer': {'max_size': 100000, 'action_dim': 1, 'n_step': 0},\n",
       " 'redo': {'attach': True,\n",
       "  'enabled': False,\n",
       "  'tau': 0.025,\n",
       "  'beta': 0.1,\n",
       "  'selection_option': None},\n",
       " 'reward_perception': None,\n",
       " 'experiment_name': 'conv32_lin128'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup config\n",
    "root_dir = os.path.dirname(os.path.abspath(\".\"))\n",
    "\n",
    "path_experiments_configs = os.path.join(\n",
    "    root_dir, \"experiments\", \"training\", \"training_configs\"\n",
    ")\n",
    "path_experiments_outputs = os.path.join(root_dir, \"experiments\", \"training\", \"outputs\")\n",
    "\n",
    "default_config_path, experiment_config_paths = get_config_paths(\n",
    "    path_experiments_configs\n",
    ")\n",
    "\n",
    "experiment_configs = read_config_files(default_config_path, experiment_config_paths)\n",
    "\n",
    "experiment_configs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = config[\"environment\"]\n",
    "\n",
    "logger = setup_logger(\n",
    "    env_name=env_name,\n",
    "    identifier_string=\"redo_test_experiment\",\n",
    ")\n",
    "logger.info(\n",
    "    f'Starting up experiment: {config[\"experiment_name\"]}, environment: {config[\"environment\"]}, seed: {config[\"seed\"]}'\n",
    ")\n",
    "\n",
    "### Setup environments ###\n",
    "train_env = build_environment(\n",
    "    game_name=config[\"environment\"], random_seed=config[\"seed\"]\n",
    ")\n",
    "validation_env = build_environment(\n",
    "    game_name=config[\"environment\"], random_seed=config[\"seed\"]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
