{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "proj_root = os.path.dirname(os.path.abspath(\".\"))\n",
    "# print(proj_root)\n",
    "sys.path.append(proj_root)\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "import torch\n",
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from pathlib import Path\n",
    "import argparse\n",
    "\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import gym\n",
    "import yaml\n",
    "\n",
    "from minatar_dqn.my_dqn import AgentDQN\n",
    "from minatar_dqn.replay_buffer import ReplayBuffer\n",
    "from minatar_dqn.utils.my_logging import setup_logger\n",
    "from minatar_dqn.models import Conv_QNET, Conv_QNET_one\n",
    "\n",
    "from experiments.experiment_utils import (\n",
    "    seed_everything,\n",
    "    search_files_containing_string,\n",
    "    split_path_at_substring,\n",
    "    collect_training_output_files,\n",
    ")\n",
    "\n",
    "from minatar_dqn.my_dqn import Conv_QNET, build_environment\n",
    "from minatar_dqn.redo import apply_redo_parametrization\n",
    "from experiments.experiment_utils import (\n",
    "    collect_training_output_files,\n",
    "    collect_pruning_output_files,\n",
    ")\n",
    "\n",
    "from experiments.training.training import read_config_files, get_config_paths\n",
    "\n",
    "from flatten_dict import flatten\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "\n",
    "sns.set()\n",
    "\n",
    "import plotly\n",
    "\n",
    "plotly.io.kaleido.scope.mathjax = None\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epochs_to_train': 20,\n",
       " 'seeds': [0],\n",
       " 'environments': ['breakout'],\n",
       " 'agent_params': {'agent': 'AgentDQN',\n",
       "  'args_': {'train_step_cnt': 200000,\n",
       "   'validation_enabled': True,\n",
       "   'validation_step_cnt': 125000,\n",
       "   'validation_epsilon': 0.001,\n",
       "   'replay_start_size': 5000,\n",
       "   'batch_size': 32,\n",
       "   'training_freq': 4,\n",
       "   'target_model_update_freq': 100,\n",
       "   'loss_fcn': 'mse_loss',\n",
       "   'gamma': 0.99,\n",
       "   'epsilon': {'start': 1.0, 'end': 0.01, 'decay': 250000}}},\n",
       " 'estimator': {'model': 'Conv_QNET',\n",
       "  'args_': {'conv_hidden_out_size': 32, 'lin_hidden_out_size': 128}},\n",
       " 'optim': {'name': 'Adam', 'args_': {'lr': 6.25e-05, 'eps': 0.00015}},\n",
       " 'replay_buffer': {'max_size': 100000, 'action_dim': 1, 'n_step': 0},\n",
       " 'redo': {'attach': True,\n",
       "  'enabled': False,\n",
       "  'tau': 0.025,\n",
       "  'beta': 0.1,\n",
       "  'selection_option': None},\n",
       " 'reward_perception': None,\n",
       " 'experiment_name': 'conv32_lin128'}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setup config\n",
    "root_dir = os.path.dirname(os.path.abspath(\".\"))\n",
    "\n",
    "path_experiments_configs = os.path.join(\n",
    "    root_dir, \"experiments\", \"training\", \"training_configs\"\n",
    ")\n",
    "path_experiments_outputs = os.path.join(root_dir, \"experiments\", \"training\", \"outputs\")\n",
    "\n",
    "default_config_path, experiment_config_paths = get_config_paths(\n",
    "    path_experiments_configs\n",
    ")\n",
    "\n",
    "experiment_configs = read_config_files(default_config_path, experiment_config_paths)\n",
    "\n",
    "experiment_configs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = experiment_configs[0]\n",
    "config[\"environment\"] = \"breakout\"\n",
    "config[\"seed\"] = 0\n",
    "\n",
    "output_path = os.path.join(\n",
    "    root_dir,\n",
    "    \"experiments\",\n",
    "    \"redo\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-10-30 22:50:18,312 - root - INFO - redo_test_experiment - Starting up experiment: conv32_lin128, environment: breakout, seed: 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chainsword\\anaconda3\\envs\\general\\lib\\site-packages\\gym\\envs\\registration.py:555: UserWarning:\n",
      "\n",
      "\u001b[33mWARN: The environment MinAtar/Breakout-v0 is out of date. You should consider upgrading to version `v1`.\u001b[0m\n",
      "\n",
      "c:\\Users\\Chainsword\\anaconda3\\envs\\general\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:20: UserWarning:\n",
      "\n",
      "\u001b[33mWARN: It seems a Box observation space is an image but the `dtype` is not `np.uint8`, actual type: bool. If the Box observation space is not an image, we recommend flattening the observation to have only a 1D vector.\u001b[0m\n",
      "\n",
      "c:\\Users\\Chainsword\\anaconda3\\envs\\general\\lib\\site-packages\\gym\\utils\\passive_env_checker.py:25: UserWarning:\n",
      "\n",
      "\u001b[33mWARN: It seems a Box observation space is an image but the upper and lower bounds are not in [0, 255]. Generally, CNN policies assume observations are within that range, so you may encounter an issue if the observation values are not.\u001b[0m\n",
      "\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'output_path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32md:\\Work\\repos\\RL\\minatar_work\\notebooks\\test_redo.ipynb Cell 4\u001b[0m line \u001b[0;36m2\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/repos/RL/minatar_work/notebooks/test_redo.ipynb#W0sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m train_env \u001b[39m=\u001b[39m build_environment(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/repos/RL/minatar_work/notebooks/test_redo.ipynb#W0sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     game_name\u001b[39m=\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39menvironment\u001b[39m\u001b[39m\"\u001b[39m], random_seed\u001b[39m=\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mseed\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/repos/RL/minatar_work/notebooks/test_redo.ipynb#W0sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/repos/RL/minatar_work/notebooks/test_redo.ipynb#W0sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m validation_env \u001b[39m=\u001b[39m build_environment(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/repos/RL/minatar_work/notebooks/test_redo.ipynb#W0sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m     game_name\u001b[39m=\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39menvironment\u001b[39m\u001b[39m\"\u001b[39m], random_seed\u001b[39m=\u001b[39mconfig[\u001b[39m\"\u001b[39m\u001b[39mseed\u001b[39m\u001b[39m\"\u001b[39m]\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/repos/RL/minatar_work/notebooks/test_redo.ipynb#W0sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/repos/RL/minatar_work/notebooks/test_redo.ipynb#W0sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m experiment_agent \u001b[39m=\u001b[39m AgentDQN(\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/repos/RL/minatar_work/notebooks/test_redo.ipynb#W0sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     train_env\u001b[39m=\u001b[39mtrain_env,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/repos/RL/minatar_work/notebooks/test_redo.ipynb#W0sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m     validation_env\u001b[39m=\u001b[39mvalidation_env,\n\u001b[1;32m---> <a href='vscode-notebook-cell:/d%3A/Work/repos/RL/minatar_work/notebooks/test_redo.ipynb#W0sZmlsZQ%3D%3D?line=21'>22</a>\u001b[0m     experiment_output_folder\u001b[39m=\u001b[39moutput_path,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/repos/RL/minatar_work/notebooks/test_redo.ipynb#W0sZmlsZQ%3D%3D?line=22'>23</a>\u001b[0m     experiment_name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mredo_test_experiment\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/repos/RL/minatar_work/notebooks/test_redo.ipynb#W0sZmlsZQ%3D%3D?line=23'>24</a>\u001b[0m     resume_training_path\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/repos/RL/minatar_work/notebooks/test_redo.ipynb#W0sZmlsZQ%3D%3D?line=24'>25</a>\u001b[0m     save_checkpoints\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/repos/RL/minatar_work/notebooks/test_redo.ipynb#W0sZmlsZQ%3D%3D?line=25'>26</a>\u001b[0m     logger\u001b[39m=\u001b[39mlogger,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/repos/RL/minatar_work/notebooks/test_redo.ipynb#W0sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m     config\u001b[39m=\u001b[39mconfig,\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/repos/RL/minatar_work/notebooks/test_redo.ipynb#W0sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m )\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/repos/RL/minatar_work/notebooks/test_redo.ipynb#W0sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m experiment_agent\u001b[39m.\u001b[39mtrain(train_epochs\u001b[39m=\u001b[39m\u001b[39m10\u001b[39m)\n\u001b[0;32m     <a href='vscode-notebook-cell:/d%3A/Work/repos/RL/minatar_work/notebooks/test_redo.ipynb#W0sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m logger\u001b[39m.\u001b[39minfo(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mFinished redo training experiment\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'output_path' is not defined"
     ]
    }
   ],
   "source": [
    "env_name = config[\"environment\"]\n",
    "\n",
    "logger = setup_logger(\n",
    "    env_name=env_name,\n",
    "    identifier_string=\"redo_test_experiment\",\n",
    ")\n",
    "logger.info(\n",
    "    f'Starting up experiment: {config[\"experiment_name\"]}, environment: {config[\"environment\"]}, seed: {config[\"seed\"]}'\n",
    ")\n",
    "\n",
    "### Setup environments ###\n",
    "train_env = build_environment(\n",
    "    game_name=config[\"environment\"], random_seed=config[\"seed\"]\n",
    ")\n",
    "validation_env = build_environment(\n",
    "    game_name=config[\"environment\"], random_seed=config[\"seed\"]\n",
    ")\n",
    "\n",
    "experiment_agent = AgentDQN(\n",
    "    train_env=train_env,\n",
    "    validation_env=validation_env,\n",
    "    experiment_output_folder=output_path,\n",
    "    experiment_name=\"redo_test_experiment\",\n",
    "    resume_training_path=None,\n",
    "    save_checkpoints=True,\n",
    "    logger=logger,\n",
    "    config=config,\n",
    ")\n",
    "\n",
    "experiment_agent.train(train_epochs=10)\n",
    "\n",
    "logger.info(f\"Finished redo training experiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "general",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
