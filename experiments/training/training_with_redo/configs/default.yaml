experiment: "redo_experiment"

epochs_to_train: 20
environment: [breakout, space_invaders, asterix]

agent_params:
  agent: AgentDQN
  args_:
    train_step_cnt: 200_000
    validation_enabled: True
    validation_step_cnt: 125_000
    validation_epsilon: 0.001
    replay_start_size: 5_000
    
    batch_size: 32
    training_freq: 4
    target_model_update_freq: 4000
    loss_fcn: mse_loss

    gamma: 0.99 
    
    epsilon:
      start: 1.0
      end: 0.01
      decay: 250_000

estimator:
  model: Conv_QNET
  args_:
    conv_hidden_out_size: 32
    lin_hidden_out_size: 128

optim:
  name: Adam
  args_:
    lr: 0.00025
    eps: 0.0003125

replay_buffer:
  max_size: 100_000
  action_dim: 1
  n_step: 0

redo:
  attach: True
  enabled: True
  tau: 0.1
  beta: 1
  redo_freq: 1_000
  selection_option: null

reward_perception: null